version: "3.9"

services:
  backend:
    build: ./backend
    container_name: chatbot-backend
    ports:
      - "5000:5000"
    environment:
      - BASE_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
      - ADAPTER_PATH=/app/tinyllama-qlora-finetuned
    volumes:
      - ./backend/tinyllama-qlora-finetuned:/app/tinyllama-qlora-finetuned:ro
    # enable GPU access (requires NVIDIA runtime & container toolkit)
    deploy: {}
    gpus: all

  frontend:
    build: ./frontend
    container_name: chatbot-frontend
    ports:
      - "8080:80"
    depends_on:
      - backend
